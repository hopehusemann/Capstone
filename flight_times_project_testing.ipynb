{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a048da81-eef5-476f-acac-cdd267298455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import os\n",
    "import tarfile\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8996d87-0a7a-4d25-8579-847af21991cd",
   "metadata": {},
   "source": [
    "## Combining all flight_data .csv files into one, 'flight_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db557893-1e3c-4f4a-b3d5-a0438164945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing CSV files\n",
    "folder_path = r'C:\\Users\\hopeh\\Desktop\\DS_Bootcamp\\Flight_times_project\\flight_data'\n",
    "\n",
    "# List to hold individual DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Read each CSV file and append to the list\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv('flight_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "450ee84d-6532-4f84-9d24-6e0df4171a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 13662099\n",
      "Number of columns: 44\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('flight_data.csv', low_memory=False)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "num_rows, num_columns = df.shape\n",
    "\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b9fa12-9c59-4a7a-b9ff-a2d412da8a1c",
   "metadata": {},
   "source": [
    "## Read weather data file ghcnd_all.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b072aa6d-09b5-47b2-817d-c43ca11c2221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    AE000041196  20240101  TMAX  278 Unnamed: 4 Unnamed: 5  S  Unnamed: 7\n",
      "0   AE000041196  20240101  TMIN  182        NaN        NaN  S         NaN\n",
      "1   AE000041196  20240101  PRCP    0          D        NaN  S         NaN\n",
      "2   AE000041196  20240101  TAVG  236          H        NaN  S         NaN\n",
      "3   AEM00041194  20240101  TMAX  277        NaN        NaN  S         NaN\n",
      "4   AEM00041194  20240101  TMIN  208        NaN        NaN  S         NaN\n",
      "5   AEM00041194  20240101  PRCP    0        NaN        NaN  S         NaN\n",
      "6   AEM00041194  20240101  TAVG  246          H        NaN  S         NaN\n",
      "7   AEM00041217  20240101  TMAX  271        NaN        NaN  S         NaN\n",
      "8   AEM00041217  20240101  TMIN  206        NaN        NaN  S         NaN\n",
      "9   AEM00041217  20240101  TAVG  238          H        NaN  S         NaN\n",
      "10  AEM00041218  20240101  TMAX  275        NaN        NaN  S         NaN\n",
      "11  AEM00041218  20240101  TMIN  179        NaN        NaN  S         NaN\n",
      "12  AEM00041218  20240101  TAVG  221          H        NaN  S         NaN\n",
      "13  AG000060390  20240101  TMIN   75        NaN        NaN  S         NaN\n",
      "14  AG000060390  20240101  TAVG  118          H        NaN  S         NaN\n",
      "15  AG000060590  20240101  TMIN   17        NaN        NaN  S         NaN\n",
      "16  AG000060590  20240101  TAVG  107          H        NaN  S         NaN\n",
      "17  AG000060611  20240101  TAVG  122          H        NaN  S         NaN\n",
      "18  AGE00147708  20240101  TMIN   80        NaN        NaN  S         NaN\n",
      "19  AGE00147708  20240101  PRCP    0        NaN        NaN  S         NaN\n"
     ]
    }
   ],
   "source": [
    "# # Read the gzip-compressed CSV file into a DataFrame\n",
    "# gzip_file_path = r'C:\\Users\\hopeh\\Desktop\\DS_Bootcamp\\Flight_times_project\\weather_data\\2024.csv.gz'\n",
    "# df = pd.read_csv(gzip_file_path, compression='gzip')\n",
    "\n",
    "# # Display the first few rows of the DataFrame\n",
    "# print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2427ddc-489a-49db-a9c5-1cb0d6f189d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to C:\\Users\\hopeh\\Desktop\\DS_Bootcamp\\Flight_times_project\\weather_data\\ghcnd_all\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Path to weather data file: ghcnd_all.tar.gz\n",
    "file_path = r'C:\\Users\\hopeh\\Desktop\\DS_Bootcamp\\Flight_times_project\\weather_data\\ghcnd_all.tar.gz'\n",
    "extract_path = r'C:\\Users\\hopeh\\Desktop\\DS_Bootcamp\\Flight_times_project\\weather_data\\ghcnd_all'\n",
    "\n",
    "# Extract the tar.gz file\n",
    "with tarfile.open(file_path, 'r:gz') as tar:\n",
    "    tar.extractall(path=extract_path)\n",
    "\n",
    "print(f\"Files extracted to {extract_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c844780-8f10-4375-8365-73e1ec390007",
   "metadata": {},
   "source": [
    "Convert weather data to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60608ac6-3747-47d4-9bef-a2af4fdbc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_dir = \"C:/Users/hopeh/Desktop/DS_Bootcamp/Flight_times_project/weather_data/ghcnd_all/ghcnd_all\"\n",
    "\n",
    "start_date = pd.to_datetime('2022-05-01')\n",
    "end_date = pd.to_datetime('2024-04-30')\n",
    "\n",
    "# List all .dly files in the directory\n",
    "all_dly_files = [f for f in os.listdir(data_dir) if f.endswith('.dly')]\n",
    "\n",
    "# Define column names\n",
    "colnames = [\"ID\", \"YEAR\", \"MONTH\"] + [f\"VALUE{i+1}\" for i in range(31)] + \\\n",
    "           [f\"MFLAG{i+1}\" for i in range(31)] + [f\"QFLAG{i+1}\" for i in range(31)] + \\\n",
    "           [f\"SFLAG{i+1}\" for i in range(31)]\n",
    "\n",
    "# Define column widths based on fixed-width format\n",
    "col_widths = [11, 4, 2] + [8] * 31 * 4  # Adjust widths as necessary\n",
    "\n",
    "def process_file(file_path):\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    results = []\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_fwf(file_path, widths=col_widths, header=None, skip_blank_lines=True)\n",
    "        data.columns = colnames\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"ParserError: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if there's a parsing error\n",
    "\n",
    "    print(f\"File {file_path} loaded, processing rows...\")\n",
    "    for _, row in data.iterrows():\n",
    "        station_id = row['ID']\n",
    "        year = row['YEAR']\n",
    "        month = row['MONTH']\n",
    "\n",
    "        for day in range(1, 32):\n",
    "            value_col = f\"VALUE{day}\"\n",
    "            mflag_col = f\"MFLAG{day}\"\n",
    "            \n",
    "            value = row[value_col]\n",
    "            mflag = row[mflag_col]\n",
    "            \n",
    "            if pd.notna(value):\n",
    "                date_str = f\"{year}-{month:02d}-{day:02d}\"\n",
    "                \n",
    "                try:\n",
    "                    # Attempt to parse the date\n",
    "                    date = pd.to_datetime(date_str, format='mixed', errors='raise')\n",
    "                    \n",
    "                    if start_date <= date <= end_date:\n",
    "                        result = {\n",
    "                            'STATION': station_id,\n",
    "                            'DATE': date.strftime('%Y-%m-%d'),\n",
    "                            'TMAX': value if mflag == \"TMAX\" else None,\n",
    "                            'TMIN': value if mflag == \"TMIN\" else None,\n",
    "                            'TAVG': value if mflag == \"TAVG\" else None,\n",
    "                            'PRCP': value if mflag == \"PRCP\" else None,\n",
    "                            'SNOW': value if mflag == \"SNOW\" else None,\n",
    "                            'AWND': value if mflag == \"AWND\" else None\n",
    "                        }\n",
    "                        results.append(result)\n",
    "                except ValueError as e:\n",
    "                    print(f\"DateParseError: {e} for date {date_str}\")\n",
    "                    continue  # Skip this date if it's invalid\n",
    "    if len(results) % 1000 == 0:\n",
    "            print(f\"Processed {len(results)} rows...\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Process all .dly files and collect data\n",
    "all_data = []\n",
    "for file in all_dly_files:\n",
    "    df = process_file(os.path.join(data_dir, file))\n",
    "    if not df.empty:\n",
    "        all_data.append(df)\n",
    "\n",
    "if all_data:\n",
    "    all_data_combined = pd.concat(all_data, ignore_index=True)\n",
    "    all_data_combined.to_csv('ghcn_daily_filtered.csv', index=False)\n",
    "else:\n",
    "    print(\"No data to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed70de-522d-457e-8534-eb205ba94605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
