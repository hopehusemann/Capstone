{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa378cd8-024c-4892-bb29-7f32a2f6a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da94f22-538a-4f83-84b3-7c563cc3a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "flights_data = pd.read_csv(r\"C:\\Users\\hopeh\\Desktop\\data_science_bootcamp\\flight_times_capstone\\flights_airport_iata.csv\", low_memory=False)\n",
    "weather_data = pd.read_csv(r\"C:\\Users\\hopeh\\Desktop\\data_science_bootcamp\\flight_times_capstone\\weather_iata.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5192a49d-50a7-4a9b-a583-d6d35acb95bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['day_of_week', 'date', 'op_unique_carrier', 'tail_num',\n",
      "       'op_carrier_fl_num', 'origin_iata', 'origin_city', 'dest_iata',\n",
      "       'dest_city', 'crs_dep_time', 'dep_time', 'taxi_out', 'wheels_off',\n",
      "       'wheels_on', 'taxi_in', 'crs_arr_time', 'arr_time', 'cancelled',\n",
      "       'diverted', 'crs_elapsed_time', 'actual_elapsed_time', 'air_time',\n",
      "       'flights', 'distance', 'distance_group', 'carrier_delay',\n",
      "       'weather_delay', 'nas_delay', 'security_delay', 'late_aircraft_delay',\n",
      "       'origin_state', 'dest_state', 'iata', 'latitude', 'longitude',\n",
      "       'iata_dest', 'airport_name_dest', 'latitude_dest', 'longitude_dest',\n",
      "       'state_abbr_dest', 'airport_ref', 'airport_ident', 'type_of_airport',\n",
      "       'airport_name', 'elevation_ft', 'origin_state.1', 'municipality',\n",
      "       'scheduled_service', 'unique_id', 'id', 'length_ft', 'width_ft',\n",
      "       'surface', 'lighted', 'closed', 'le_ident', 'le_displaced_threshold_ft',\n",
      "       'he_ident', 'he_displaced_threshold_ft'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(flights_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1feccc3f-5104-4d31-9e76-096a895c608e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['latitude', 'longitude', 'elevation', 'date', 'prcp', 'snow', 'snwd',\n",
      "       'tmax', 'tmin', 'tobs', 'city', 'state_abbr_x', 'iata', 'airport_name',\n",
      "       'state_abbr_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(weather_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d179db9-8c2c-49a4-82b7-4328499e17a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['day_of_week', 'date', 'op_unique_carrier', 'tail_num',\n",
      "       'op_carrier_fl_num', 'origin_iata', 'origin_city', 'dest_iata',\n",
      "       'dest_city', 'crs_dep_time', 'dep_time', 'taxi_out', 'wheels_off',\n",
      "       'wheels_on', 'taxi_in', 'crs_arr_time', 'arr_time', 'cancelled',\n",
      "       'diverted', 'crs_elapsed_time', 'actual_elapsed_time', 'air_time',\n",
      "       'flights', 'distance', 'distance_group', 'carrier_delay',\n",
      "       'weather_delay', 'nas_delay', 'security_delay', 'late_aircraft_delay',\n",
      "       'origin_state', 'dest_state', 'iata', 'origin_latitude',\n",
      "       'origin_longitude', 'iata_dest', 'airport_name_dest', 'dest_latitude',\n",
      "       'dest_longitude', 'state_abbr_dest', 'airport_ref', 'airport_ident',\n",
      "       'type_of_airport', 'airport_name', 'elevation_ft', 'origin_state.1',\n",
      "       'municipality', 'scheduled_service', 'unique_id', 'id', 'length_ft',\n",
      "       'width_ft', 'surface', 'lighted', 'closed', 'le_ident',\n",
      "       'le_displaced_threshold_ft', 'he_ident', 'he_displaced_threshold_ft'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rename columns in flights_data\n",
    "flights_data = flights_data.rename(columns={\n",
    "    'latitude': 'origin_latitude',\n",
    "    'longitude': 'origin_longitude',\n",
    "    'latitude_dest': 'dest_latitude',\n",
    "    'longitude_dest': 'dest_longitude'\n",
    "})\n",
    "\n",
    "# Check the updated columns to confirm the changes\n",
    "print(flights_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ceb36de4-80e6-4d65-9a40-cf3d74b17f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging with origin weather:\n",
      "Index(['day_of_week', 'date', 'op_unique_carrier', 'tail_num',\n",
      "       'op_carrier_fl_num', 'origin_iata', 'origin_city', 'dest_iata',\n",
      "       'dest_city', 'crs_dep_time', 'dep_time', 'taxi_out', 'wheels_off',\n",
      "       'wheels_on', 'taxi_in', 'crs_arr_time', 'arr_time', 'cancelled',\n",
      "       'diverted', 'crs_elapsed_time', 'actual_elapsed_time', 'air_time',\n",
      "       'flights', 'distance', 'distance_group', 'carrier_delay',\n",
      "       'weather_delay', 'nas_delay', 'security_delay', 'late_aircraft_delay',\n",
      "       'origin_state', 'dest_state', 'iata', 'origin_latitude',\n",
      "       'origin_longitude', 'iata_dest', 'airport_name_dest', 'dest_latitude',\n",
      "       'dest_longitude', 'state_abbr_dest', 'airport_ref', 'airport_ident',\n",
      "       'type_of_airport', 'airport_name', 'elevation_ft', 'origin_state.1',\n",
      "       'municipality', 'scheduled_service', 'unique_id', 'id', 'length_ft',\n",
      "       'width_ft', 'surface', 'lighted', 'closed', 'le_ident',\n",
      "       'le_displaced_threshold_ft', 'he_ident', 'he_displaced_threshold_ft',\n",
      "       'latitude', 'longitude', 'elevation', 'prcp', 'snow', 'snwd', 'tmax',\n",
      "       'tmin', 'tobs', 'city', 'state_abbr_x', 'iata_origin',\n",
      "       'airport_name_origin', 'state_abbr_y', 'latitude_dest',\n",
      "       'longitude_dest', 'elevation_dest', 'prcp_dest', 'snow_dest',\n",
      "       'snwd_dest', 'tmax_dest', 'tmin_dest', 'tobs_dest', 'city_dest',\n",
      "       'state_abbr_x_dest', 'iata_dest', 'airport_name_dest',\n",
      "       'state_abbr_y_dest'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# flights_data should contain at least 'origin_iata', 'dest_iata', and 'date'\n",
    "# weather_data should contain 'iata', 'date', and weather columns\n",
    "# Merge for origin weather data\n",
    "origin_data = flights_data.merge(\n",
    "    weather_data,\n",
    "    left_on=['date', 'origin_iata'],\n",
    "    right_on=['date', 'iata'],\n",
    "    how='left',\n",
    "    suffixes=('', '_origin')\n",
    ")\n",
    "\n",
    "# Check the columns after the merge\n",
    "print(\"After merging with origin weather:\")\n",
    "print(combined_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b649de2e-7e40-4422-a2f9-4400c3d5d3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging with destination weather:\n",
      "Index(['day_of_week', 'date', 'op_unique_carrier', 'tail_num',\n",
      "       'op_carrier_fl_num', 'origin_iata', 'origin_city', 'dest_iata',\n",
      "       'dest_city', 'crs_dep_time', 'dep_time', 'taxi_out', 'wheels_off',\n",
      "       'wheels_on', 'taxi_in', 'crs_arr_time', 'arr_time', 'cancelled',\n",
      "       'diverted', 'crs_elapsed_time', 'actual_elapsed_time', 'air_time',\n",
      "       'flights', 'distance', 'distance_group', 'carrier_delay',\n",
      "       'weather_delay', 'nas_delay', 'security_delay', 'late_aircraft_delay',\n",
      "       'origin_state', 'dest_state', 'iata', 'origin_latitude',\n",
      "       'origin_longitude', 'iata_dest', 'airport_name_dest', 'dest_latitude',\n",
      "       'dest_longitude', 'state_abbr_dest', 'airport_ref', 'airport_ident',\n",
      "       'type_of_airport', 'airport_name', 'elevation_ft', 'origin_state.1',\n",
      "       'municipality', 'scheduled_service', 'unique_id', 'id', 'length_ft',\n",
      "       'width_ft', 'surface', 'lighted', 'closed', 'le_ident',\n",
      "       'le_displaced_threshold_ft', 'he_ident', 'he_displaced_threshold_ft',\n",
      "       'latitude', 'longitude', 'elevation', 'prcp', 'snow', 'snwd', 'tmax',\n",
      "       'tmin', 'tobs', 'city', 'state_abbr_x', 'iata_origin',\n",
      "       'airport_name_origin', 'state_abbr_y', 'latitude_dest',\n",
      "       'longitude_dest', 'elevation_dest', 'prcp_dest', 'snow_dest',\n",
      "       'snwd_dest', 'tmax_dest', 'tmin_dest', 'tobs_dest', 'city_dest',\n",
      "       'state_abbr_x_dest', 'iata_dest', 'airport_name_dest',\n",
      "       'state_abbr_y_dest'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Merge for destination weather data\n",
    "combined_data = origin_data.merge(\n",
    "    weather_data,\n",
    "    left_on=['date', 'dest_iata'],\n",
    "    right_on=['date', 'iata'],\n",
    "    how='left',\n",
    "    suffixes=('', '_dest')\n",
    ")\n",
    "\n",
    "# Check the columns after the second merge\n",
    "print(\"After merging with destination weather:\")\n",
    "print(combined_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "711f2bb3-6a16-49e8-98ce-7f230b3bbf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [date, origin_iata, dest_iata]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for NaN rows if necessary\n",
    "nan_rows = combined_data[combined_data['iata'].isnull()]\n",
    "print(nan_rows[['date', 'origin_iata', 'dest_iata']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4c5f11ce-2946-4fd9-92cd-2961877e5b34",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.03 GiB for an array with shape (9, 15332060) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m             seen\u001b[38;5;241m.\u001b[39madd(col)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Create a new DataFrame with only unique columns\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m combined_data_cleaned \u001b[38;5;241m=\u001b[39m combined_data[unique_columns]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Display the cleaned DataFrame's columns\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns after removing duplicate columns:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4117\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   4115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 4117\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_with_is_copy(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   4119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[0;32m   4120\u001b[0m     \u001b[38;5;66;03m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[0;32m   4121\u001b[0m     \u001b[38;5;66;03m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[0;32m   4122\u001b[0m     \u001b[38;5;66;03m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[0;32m   4123\u001b[0m     \u001b[38;5;66;03m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[0;32m   4124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n\u001b[0;32m   4125\u001b[0m         \u001b[38;5;66;03m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4145\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4146\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indices\u001b[38;5;241m=\u001b[39mindices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   4154\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[0;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4131\u001b[0m     )\n\u001b[1;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[0;32m   4134\u001b[0m     indices,\n\u001b[0;32m   4135\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[0;32m   4136\u001b[0m     verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   4137\u001b[0m )\n\u001b[0;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4140\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    895\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[0;32m    896\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[0;32m    897\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    898\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    899\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    900\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:680\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    689\u001b[0m             indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:843\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[0;32m    841\u001b[0m                     blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    842\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 843\u001b[0m                 nb \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mtake_nd(taker, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, new_mgr_locs\u001b[38;5;241m=\u001b[39mmgr_locs)\n\u001b[0;32m    844\u001b[0m                 blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blocks\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m algos\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m   1308\u001b[0m     values, indexer, axis\u001b[38;5;241m=\u001b[39maxis, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[0;32m   1309\u001b[0m )\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    155\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.03 GiB for an array with shape (9, 15332060) and data type float64"
     ]
    }
   ],
   "source": [
    "unique_columns = []\n",
    "\n",
    "# Set to track seen columns\n",
    "seen = set()\n",
    "\n",
    "# Process columns in chunks\n",
    "chunk_size = 100  # Adjust this size based on your memory and performance\n",
    "for start in range(0, combined_data.shape[1], chunk_size):\n",
    "    end = min(start + chunk_size, combined_data.shape[1])\n",
    "    chunk = combined_data.iloc[:, start:end]\n",
    "    \n",
    "    # Identify duplicates in the current chunk\n",
    "    for col in chunk.columns:\n",
    "        if col not in seen:\n",
    "            unique_columns.append(col)\n",
    "            seen.add(col)\n",
    "\n",
    "# Create a new DataFrame with only unique columns\n",
    "combined_data_cleaned = combined_data[unique_columns]\n",
    "\n",
    "# Display the cleaned DataFrame's columns\n",
    "print(\"Columns after removing duplicate columns:\")\n",
    "print(combined_data_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179474e-e689-406e-afc4-c98879dc2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Keep only the unique columns\n",
    "combined_data_cleaned = combined_data.loc[:, ~duplicate_columns]\n",
    "\n",
    "# Display the cleaned DataFrame's columns\n",
    "print(\"Columns after removing duplicate columns:\")\n",
    "print(combined_data_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859eced-bd0f-4abc-8588-c587e60acfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows from the DataFrame\n",
    "combined_data_cleaned = combined_data_cleaned.drop_duplicates()\n",
    "\n",
    "# Display the shape of the cleaned DataFrame to check for changes\n",
    "print(\"Shape of DataFrame after removing duplicate rows:\")\n",
    "print(combined_data_cleaned.shape)\n",
    "\n",
    "# Optionally, display the first few rows to verify\n",
    "print(\"First few rows of the cleaned DataFrame:\")\n",
    "print(combined_data_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bace85-f7bb-4f10-ace3-e24f0975ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = combined_data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc67bc95-4f5d-4d0e-8970-c4449566931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e8fb55-d079-428c-b0eb-0fd473636253",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_data.shape)\n",
    "print(weather_data.shape())\n",
    "print(flight_data.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefee2a-dac3-451a-ae44-20b5283d62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b58a6d-f44d-4cf7-adce-b88583f2b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(combined_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc36a53-4b0e-4bca-a84f-45100b95f692",
   "metadata": {},
   "source": [
    "Flights Data:\n",
    "Carrier Delay:\n",
    "Imputation: If you believe the missing values might be due to missing reports rather than actual absence of delay, consider imputing these values with the average delay for that airline or flight.\n",
    "Drop: If the missing values are too many and could skew your analysis, consider dropping the carrier_delay column if it’s not critical for your analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47015986-428c-4ee4-8442-2b151a4d1a8f",
   "metadata": {},
   "source": [
    "Weather Data:\n",
    "Snow and Snow Depth:\n",
    "Imputation: You can fill in missing values with 0 (assuming no snow) or use interpolation or forward/backward filling methods based on surrounding data.\n",
    "Drop: If a significant portion of your analysis requires snow data and the missing values are large, consider dropping those rows or the columns if they don’t contribute significantly to your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b86fd2-34d3-40d1-ab5c-8e145b0eb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of null values for each column\n",
    "null_percentage_weather = weather_data.isnull().mean() * 100\n",
    "\n",
    "# Filter to show only columns with null values\n",
    "null_percentage_weather = null_percentage_weather[null_percentage_weather > 0]\n",
    "\n",
    "# Display the result\n",
    "print(null_percentage_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e6015-80b5-4a46-ac65-b16c03bbb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of null values for each column\n",
    "null_percentage_flights = combined_data.isnull().mean() * 100\n",
    "\n",
    "# Filter to show only columns with null values\n",
    "null_percentage_flights = null_percentage_flights[null_percentage_flights > 0]\n",
    "\n",
    "# Display the result\n",
    "print(null_percentage_flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f03c0a3-41f2-4efc-93cc-00828a1c5022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"Number of combined_data duplicates: \" + str(combined_data.duplicated().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33348c-2ef6-40c2-8318-44492809ae0d",
   "metadata": {},
   "source": [
    "Investigating duplicate rows: By conducting these analyses, I am trying to identify whether there are any underlying issues with the data that could be contributing to the duplicates and gain a clearer understanding of the variability present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41bd0d6-864a-4124-a6c2-69cffd374211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying outliers\n",
    "\n",
    "Q1 = flights_weather_df['total_delay_time'].quantile(0.25)\n",
    "Q3 = flights_weather_df['total_delay_time'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out outliers\n",
    "outliers = flights_weather_df[(flights_weather_df['total_delay_time'] < lower_bound) | (flights_weather_df['total_delay_time'] > upper_bound)]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=flights_data['total_delay_time'])\n",
    "plt.title('Box Plot of Total Delay Time')\n",
    "plt.axvline(0, color='red', linestyle='--')  # Line at zero for reference\n",
    "plt.show()\n",
    "\n",
    "print(\"Outliers:\")\n",
    "print(outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141584a-99c9-4769-824a-c526e7ea4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "\n",
    "# Create new features\n",
    "combined_data['total_delay_time'] = combined_data['actual_elapsed_time'] - combined_data['crs_elapsed_time']\n",
    "combined_data['is_weekend'] = combined_data['day_of_week'].isin([5, 6]).astype(int)  # Saturday and Sunday\n",
    "\n",
    "# Assuming crs_arr_time and arr_time are in HHMM format, convert them to minutes\n",
    "combined_data['crs_arr_time'] = combined_data['crs_arr_time'] // 100 * 60 + combined_data['crs_arr_time'] % 100\n",
    "combined_data['arr_time'] = combined_data['arr_time'] // 100 * 60 + combined_data['arr_time'] % 100\n",
    "\n",
    "# Calculate arrival delay\n",
    "combined_data['arrival_delay'] = combined_data['arr_time'] - combined_data['crs_arr_time']\n",
    "\n",
    "# Assuming crs_dep_time and dep_time are also in HHMM format, convert them similarly\n",
    "combined_data['crs_dep_time'] = combined_data['crs_dep_time'] // 100 * 60 + combined_data['crs_dep_time'] % 100\n",
    "combined_data['dep_time'] = combined_data['dep_time'] // 100 * 60 + combined_data['dep_time'] % 100\n",
    "\n",
    "# Calculate departure delay\n",
    "combined_data['departure_delay'] = combined_data['dep_time'] - combined_data['crs_dep_time']\n",
    "\n",
    "# Set the plot style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Create subplots for arrival and departure delays\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# Plotting Arrival Delays\n",
    "sns.histplot(combined_data['arrival_delay'], bins=50, kde=True, color='blue', ax=axes[0])\n",
    "axes[0].set_title('Distribution of Arrival Delays', fontsize=16)\n",
    "axes[0].set_xlabel('Arrival Delay (minutes)', fontsize=14)\n",
    "axes[0].set_ylabel('Frequency', fontsize=14)\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', label='On-Time')\n",
    "# Set the limits for the x-axis\n",
    "plt.xlim(-25, 25)  # Adjust based on the distribution\n",
    "axes[0].legend()\n",
    "\n",
    "# Plotting Departure Delays\n",
    "sns.histplot(combined_data['departure_delay'], bins=50, kde=True, color='orange', ax=axes[1])\n",
    "axes[1].set_title('Distribution of Departure Delays', fontsize=16)\n",
    "axes[1].set_xlabel('Departure Delay (minutes)', fontsize=14)\n",
    "axes[1].set_ylabel('Frequency', fontsize=14)\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', label='On-Time')\n",
    "# Set the limits for the x-axis\n",
    "plt.xlim(-25, 25)  # Adjust based on the distribution\n",
    "axes[1].legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbcde71-133c-4dae-925f-a27fd160532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all duplicate rows\n",
    "duplicate_rows = weather_data[weather_data.duplicated(keep=False)]\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be84d066-2b17-4ecc-918d-136775a5a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicates and sort by count\n",
    "duplicate_counts = weather_data[weather_data.duplicated(keep=False)].groupby(weather_data.columns.tolist()).size().reset_index(name='count')\n",
    "duplicate_counts = duplicate_counts.sort_values(by='count', ascending=False)\n",
    "print(duplicate_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd5657-8cff-4a4b-b4d6-15aa4d6a5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duplicate_rows[['date', 'iata', 'prcp', 'tmax', 'tmin']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f33f79-514a-48c5-97ff-aea48987e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180dfca0-e8a9-4bc8-95ef-37a5d2102df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duplicate_rows.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5571476f-7685-4726-9b37-3be6599e448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=duplicate_rows, x='tmax')\n",
    "plt.title('Distribution of Max Temperature in Duplicates')\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(duplicate_rows['prcp'], bins=30)\n",
    "plt.title('Histogram of Precipitation in Duplicates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f3c6b-2e83-465c-9ec2-1b18a818c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group the duplicates by the key columns (e.g., date, iata) and aggregate to see how values differ.\n",
    "grouped_duplicates = duplicate_rows.groupby(['date', 'iata']).agg({'prcp': 'mean', 'tmax': 'mean', 'tmin': 'mean', 'snow': 'mean'}).reset_index()\n",
    "print(grouped_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a61cf-6856-4ef5-b338-1236801339a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many unique values exist for certain columns within the duplicates to see if there’s variability.\n",
    "print(duplicate_rows.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0133e0c-daae-4076-ac6f-fa1b7b62a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all duplicate rows\n",
    "duplicate_rows = flights_data[flights_data.duplicated(keep=False)]\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db7c79-74ec-41e7-9621-2512f1b4e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identify which iata codes have the most variability in latitude and longitude.\n",
    "\n",
    "# # Check the columns in duplicate_rows\n",
    "# print(duplicate_rows.columns)\n",
    "\n",
    "# # Ensure 'latitude' and 'longitude' are present\n",
    "# if 'latitude' in duplicate_rows.columns and 'longitude' in duplicate_rows.columns:\n",
    "#     # Group by IATA code and count unique latitude and longitude values\n",
    "#     lat_lon_variability = duplicate_rows.groupby('origin_iata').agg({\n",
    "#         'latitude': 'nunique',\n",
    "#         'longitude': 'nunique'\n",
    "#     }).reset_index()\n",
    "\n",
    "#     # Rename columns for clarity\n",
    "#     lat_lon_variability.columns = ['iata', 'unique_latitudes', 'unique_longitudes']\n",
    "\n",
    "#     # Filter for IATA codes with more than one unique latitude or longitude\n",
    "#     variability_filter = lat_lon_variability[(lat_lon_variability['unique_latitudes'] > 1) | \n",
    "#                                              (lat_lon_variability['unique_longitudes'] > 1)]\n",
    "\n",
    "#     print(\"IATA codes with variability in latitude or longitude:\")\n",
    "#     print(variability_filter)\n",
    "# else:\n",
    "#     print(\"Columns 'latitude' or 'longitude' do not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840d64d-49ec-4f89-b25f-e829de6847b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if certain dates have more duplicates and how they vary in terms of weather conditions.\n",
    "date_variability = duplicate_rows.groupby('date').size().reset_index(name='count')\n",
    "print(date_variability[date_variability['count'] > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8eed0b-8886-49b9-8bf0-d3f48ef3c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d9cf7-5ce7-44a0-8c43-51a2726cd76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create plots to visualize how tmax, tmin, and prcp vary over the dates for the same iata code.\n",
    "\n",
    "# # Ensure 'date' is in datetime format\n",
    "# duplicate_rows.loc[:, 'date'] = pd.to_datetime(duplicate_rows['date'])\n",
    "\n",
    "# # Plot Max Temperature (tmax)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.lineplot(data=duplicate_rows, x='date', y='tmax', hue='origin_iata', marker='o')\n",
    "# plt.title('Max Temperature Over Time for Duplicate Entries')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Max Temperature (°F)')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.legend(title='IATA Code')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b2ce2f-69ef-4d45-b731-a97107132996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Plot Min Temperature (tmin)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.lineplot(data=duplicate_rows, x='date', y='tmin', hue='origin_iata', marker='o')\n",
    "# plt.title('Min Temperature Over Time for Duplicate Entries')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Min Temperature (°F)')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.legend(title='IATA Code')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot Precipitation (prcp)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.lineplot(data=duplicate_rows, x='date', y='prcp', hue='origin_iata', marker='o')\n",
    "# plt.title('Precipitation Over Time for Duplicate Entries')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Precipitation (inches)')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.legend(title='IATA Code')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8ed35-1222-4c33-8dfc-79a6dbda24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure that each iata code consistently points to the same airport name, latitude, longitude, and elevation.\n",
    "# consistency_check = duplicate_rows.groupby('iata')[['latitude', 'longitude', 'elevation']].nunique()\n",
    "# print(consistency_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd40feb-071a-4f98-96e8-b744c88017b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing Values: fill or drop missing values (e.g., mean, median, mode, or dropping rows/columns)\n",
    "\n",
    "# Drop duplicate rows, keeping the first occurrence\n",
    "weather_data = weather_data.drop_duplicates(keep='first')\n",
    "\n",
    "# Reset the index after dropping duplicates\n",
    "weather_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(weather_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211daef-cf96-4c3e-ae74-9f2ab6bf3f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows, keeping the first occurrence\n",
    "flights_data = flights_data.drop_duplicates(keep='first')\n",
    "\n",
    "# Rreset the index after dropping duplicates\n",
    "flights_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(flights_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528c3fd-adb8-428d-b65d-47cc3c9ed494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"Number of flights_data duplicates: \" + str(flights_data.duplicated().sum()))\n",
    "print(\"Number of weather_data duplicates: \" + str(weather_data.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e1d120-040a-4a69-a930-9b92ea564bfb",
   "metadata": {},
   "source": [
    "Investigating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0926e3-4d3a-497b-8300-fd5756f5fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flight_data\n",
    "# High missing values for carrier_delay, weather_delay, nas_delay, \n",
    "# security_delay, and late_aircraft_delay, but we are keeping \n",
    "# due to nature of information.\n",
    "# Moderate Missing Values: tail_num, dep_time, taxi_out, etc.: \n",
    "# These have around 1-3% missing values. Filling these with \n",
    "# the mean or median, as they are likely to still provide valuable \n",
    "# information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b03d06-585f-44f5-9edf-fbaff027f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for numerical variables using median\n",
    "for col in ['dep_time', 'taxi_out', 'wheels_off', 'wheels_on', 'taxi_in', \n",
    "            'arr_time', 'actual_elapsed_time', 'air_time']:\n",
    "    flights_data[col] = flights_data[col].fillna(flights_data[col].median())\n",
    "\n",
    "# Impute missing values for the categorical variable\n",
    "flights_data['tail_num'] = flights_data['tail_num'].fillna(flights_data['tail_num'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc1901-7fde-4ec3-8ef3-ef0d3e78597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of null values for each column\n",
    "null_percentage_flights = flights_data.isnull().mean() * 100\n",
    "\n",
    "# Filter to show only columns with null values\n",
    "null_percentage_flights = null_percentage_flights[null_percentage_flights > 0]\n",
    "\n",
    "# Display the result\n",
    "print(null_percentage_flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef8de6-9176-4a12-9eec-4248f745a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how these delays correlate with each other\n",
    "correlation_matrix = flights_data[['carrier_delay', 'weather_delay', 'nas_delay', 'security_delay', 'late_aircraft_delay']].corr()\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2086899a-be5c-4470-a873-edaeea86ddd7",
   "metadata": {},
   "source": [
    "Since the correlations are low, it implies that these types of delays do not influence each other significantly. For instance, an increase in carrier_delay does not correlate with an increase or decrease in weather_delay, nas_delay, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae7cd5-ce75-46b0-849d-32b9198cdb7c",
   "metadata": {},
   "source": [
    "Investigate Further: If you’re looking for potential factors influencing these delays, consider examining:\n",
    "\n",
    "Time of year (seasonality)\n",
    "Day of the week\n",
    "Specific routes or airlines\n",
    "Visual Analysis: Visualizing these relationships can also provide insights:\n",
    "\n",
    "Scatter plots could help visualize the relationship between two delay types, even if correlations are low.\n",
    "Boxplots can show the distribution of delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9258da9-7e46-4bf0-9c72-f985e0eaf666",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flights_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccee59f-00a2-4656-9f4f-e493f285cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique airports reporting any delays\n",
    "delay_columns = ['carrier_delay', 'weather_delay', 'nas_delay', 'security_delay', 'late_aircraft_delay']\n",
    "airports_with_delays = flights_data[delay_columns].notnull().any(axis=1)\n",
    "unique_airports = flights_data[airports_with_delays]['origin_iata'].unique() #origin airport\n",
    "print(f\"Unique airports reporting delays: {len(unique_airports)}\")\n",
    "print(unique_airports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16172395-7942-4663-9904-fc15fc70619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize null value counts for each delay type\n",
    "null_summary = flights_data[delay_columns].isnull().sum()\n",
    "print(null_summary)\n",
    "\n",
    "# Group by the correct airport column and calculate the percentage of null values\n",
    "null_percentage_by_airport = flights_data.groupby('origin_iata')[delay_columns].apply(lambda x: x.isnull().mean())\n",
    "print(null_percentage_by_airport)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc8a43-9816-4948-9aa1-2489677663a1",
   "metadata": {},
   "source": [
    "Summary of Null Values:\n",
    "\n",
    "Each delay type has a total of 3,211,353 null values, which indicates that these delays are missing for a large portion of the dataset.\n",
    "\n",
    "Percentage of Null Values by Airport:\n",
    "\n",
    "The percentages for each delay type across various airports (identified by origin_iata) are consistent. This means that for each airport, the proportion of missing values for the delay types is very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7d174-e67e-447b-b8ba-8580c93e12be",
   "metadata": {},
   "source": [
    "The consistent high percentage of null values for all delay types across different airports suggests a few possibilities:\n",
    "\n",
    "Data Reporting Issues:\n",
    "\n",
    "It’s possible that the dataset does not consistently report certain types of delays. If many flights are missing delay data, it could be that those types of delays are not applicable or not recorded for some flights.\n",
    "Flight Types:\n",
    "\n",
    "Certain types of flights (e.g., regional vs. international, or different airlines) may not report delay reasons uniformly. If a significant number of flights are not delayed for reasons recorded in these columns, the null values would be high.\n",
    "Consistent Data Collection Methods:\n",
    "\n",
    "If the data collection methods are consistent across all airports, this could also lead to similar null value patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a439f-1cc5-4e4f-808e-94c27b02458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_mapping = {\n",
    "    '9e': 'Envoy Air',\n",
    "    'aa': 'American Airlines',\n",
    "    'as': 'Alaska Airlines',\n",
    "    'b6': 'JetBlue Airways',\n",
    "    'dl': 'Delta Air Lines',\n",
    "    'f9': 'Frontier Airlines',\n",
    "    'g4': 'Allegiant Air',\n",
    "    'ha': 'Hawaiian Airlines',\n",
    "    'mq': 'Envoy Air',\n",
    "    'nk': 'Spirit Airlines',\n",
    "    'oh': 'Piedmont Airlines',\n",
    "    'oo': 'SkyWest Airlines',\n",
    "    'ua': 'United Airlines',\n",
    "    'wn': 'Southwest Airlines',\n",
    "    'yx': 'Republic Airways'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc3236-d47d-4ded-97a2-c7dea3f6a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to map codes to airport names\n",
    "def map_airline_codes(codes):\n",
    "    return airline_mapping.get(codes, 'Unknown Airline')\n",
    "\n",
    "# apply function\n",
    "flights_data['airline_name'] = flights_data['op_unique_carrier'].apply(map_airline_codes)\n",
    "\n",
    "# View the updated DataFrame\n",
    "print(flights_data[['op_unique_carrier', 'airline_name']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656289c8-f495-43c9-b547-277eb7703ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by airline, origin, and destination to count missing data\n",
    "missing_data_routes = flights_data[flights_data[delay_columns].isnull().any(axis=1)].groupby(['airline_name', 'origin_iata', 'dest_iata']).size()\n",
    "\n",
    "# Print the result\n",
    "print(missing_data_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d4b551-4427-4b49-b97b-576556125857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort results\n",
    "missing_data_routes_sorted = missing_data_routes.sort_values(ascending=False)\n",
    "print(missing_data_routes_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee286f-71a4-4830-81bb-32cdb7f947c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_routes_sorted.head(10).plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Top 10 Routes with Missing Delay Data')\n",
    "plt.xlabel('Airline, Origin, Destination')\n",
    "plt.ylabel('Number of Missing Entries')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b781c-0ddc-4ac0-aa24-3fb84ef4187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total flights per airline\n",
    "total_flights_per_airline = flights_data.groupby('airline_name').size()\n",
    "\n",
    "# Missing data analysis\n",
    "missing_data_analysis = flights_data[flights_data[delay_columns].isnull().any(axis=1)].groupby('airline_name').size()\n",
    "\n",
    "# Calculate the percentage of missing data\n",
    "missing_percentage = (missing_data_analysis / total_flights_per_airline) * 100\n",
    "\n",
    "# Combine the results into a DataFrame for easier viewing\n",
    "missing_data_summary = pd.DataFrame({\n",
    "    'Total Flights': total_flights_per_airline,\n",
    "    'Missing Data': missing_data_analysis,\n",
    "    'Missing Percentage': missing_percentage\n",
    "}).fillna(0)  # Fill NaN with 0 for airlines with no missing data\n",
    "\n",
    "# Print the summary\n",
    "print(missing_data_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec4d772-70d4-419d-86c5-84bd102ec1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate relationships further\n",
    "missing_data_routes = flights_data[flights_data[delay_columns].isnull().any(axis=1)].groupby(['airline_name', 'origin_iata', 'dest_iata']).size()\n",
    "print(missing_data_routes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313d59e-21ab-4859-beb1-4ecb9542fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_analysis.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Missing Delay Data by Airline')\n",
    "plt.xlabel('Airlines')\n",
    "plt.ylabel('Number of Missing Entries')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b438a3f-b7a4-4d71-a95e-e9d770e6217d",
   "metadata": {},
   "source": [
    "Summary of Missing Delay Data by Airline\n",
    "\n",
    "United Airlines (ua) and Southwest Airlines (wn) have the highest counts of missing delay data, with 339,040 and 638,415 entries missing, respectively.\n",
    "American Airlines (aa) and Delta Airlines (dl) also show significant numbers of missing data, with 492,133 and 478,777 entries missing.\n",
    "Other airlines like Alaska Airlines (as) and JetBlue Airways (b6) have comparatively fewer missing entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df2852-9246-42d5-a7ce-f91bed863022",
   "metadata": {},
   "source": [
    "Possible Implications:\n",
    "\n",
    "Airline Reporting Practices:\n",
    "Airlines with a high number of missing delay entries may have different reporting practices or may be less consistent in reporting specific delay reasons.\n",
    "\n",
    "Flight Type Differences:\n",
    "The airlines with fewer missing entries may have flight routes or operational practices that more consistently record delays.\n",
    "\n",
    "Potential Data Gaps:\n",
    "A large number of missing values could indicate that certain flights or routes (especially those operated by the airlines with high missing data) may have delays that are not being reported for some reason.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b43bfb9-a0c9-4132-a248-5a88d7d81c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate if there are specific routes or types of flights associated with these airlines that might also show a pattern in the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655052b8-cc44-484a-ae81-2396cc8c753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_routes = flights_data[flights_data[delay_columns].isnull().any(axis=1)].groupby(['airline_name', 'origin_iata', 'dest_iata']).size()\n",
    "print(missing_data_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf2d64-e91e-440d-bc6d-b06baa88560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate missing data by airline and route\n",
    "missing_data_summary = missing_data_routes.reset_index(name='missing_count')\n",
    "\n",
    "# Sort by missing count to find the most affected routes\n",
    "missing_data_summary = missing_data_summary.sort_values(by='missing_count', ascending=False)\n",
    "\n",
    "# Display the top routes with missing data\n",
    "print(missing_data_summary.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a162b5-9b1f-47da-9b9b-45dedcb6678e",
   "metadata": {},
   "source": [
    "weather_data\n",
    "High Missing Values: snow (64.83%) and snwd (67.21%): Since these \n",
    "represent snow-related data, they are considered critical to analysis.\n",
    "tobs (94.10%): This column has very high missing values, but we are\n",
    "leaving for now because it represents temperatures observed.\n",
    "Moderate Missing Values: elevation, prcp, tmax, tmin:\n",
    "These have around 4-5% missing values. Filling these with the mean or median.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88082d3f-9da6-44d9-9d79-5ee1792dda5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify whether there are specific routes consistently showing\n",
    "# missing data and see if they correlate with certain characteristics \n",
    "# (like flight frequency, carrier performance, etc.).\n",
    "# Plot top 10 routes with missing data\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=missing_data_summary.head(10), \n",
    "            x='missing_count', \n",
    "            y='origin_iata', \n",
    "            hue='airline_name')\n",
    "plt.title('Top 10 Routes with Missing Delay Data by Airline')\n",
    "plt.xlabel('Count of Missing Data')\n",
    "plt.ylabel('Origin IATA')\n",
    "plt.legend(title='Airline Name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f034e-fe9c-402e-b8d9-a1161f07d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by airline and calculate total missing data\n",
    "airline_missing_counts = missing_data_summary.groupby('airline_name')['missing_count'].sum().reset_index()\n",
    "\n",
    "# Sort and visualize airline performance regarding missing data\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=airline_missing_counts.sort_values(by='missing_count', ascending=False), \n",
    "            x='missing_count', \n",
    "            y='airline_name')\n",
    "plt.title('Total Missing Delay Data by Airline')\n",
    "plt.xlabel('Total Missing Count')\n",
    "plt.ylabel('Airline Name')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa6897-5d8e-45c9-abaa-eb3c326f34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate correlations between the missing data and other features, \n",
    "# like flight distance or time of year. \n",
    "\n",
    "# Merge missing data with other relevant features if available\n",
    "merged_missing_data = flights_data.merge(missing_data_summary, \n",
    "                                          on=['airline_name', 'origin_iata', 'dest_iata'], \n",
    "                                          how='left')\n",
    "\n",
    "# Analyze correlation with flight distance, for instance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=merged_missing_data, \n",
    "                x='distance', \n",
    "                y='missing_count')\n",
    "plt.title('Missing Data Count vs. Flight Distance')\n",
    "plt.xlabel('Flight Distance')\n",
    "plt.ylabel('Count of Missing Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36d3ed-84c1-4b0e-8786-97eaa9fafb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation\n",
    "correlation = merged_missing_data['missing_count'].corr(merged_missing_data['distance'])\n",
    "\n",
    "print(f'Correlation between missing data count and flight distance: {correlation}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea5bf2-543c-4a29-91d0-409a65ed101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35174edb-fc00-43c5-88a7-05cd64c52567",
   "metadata": {},
   "source": [
    "Dive deeper into the specific characteristics of the flights that are missing data, such as:\n",
    "\n",
    "Flight times: Are these flights mostly at specific times of day?\n",
    "Days of the week: Are there certain days that show higher rates of missing data?\n",
    "Airline performance: How do these routes compare to others in terms of delays and cancellations?\n",
    "This analysis will help you determine whether specific airlines or routes are associated with the missing data and identify any patterns that could inform further investigation or operational improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6475efe6-64c7-4323-8cff-e0120e58d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare data for tmax, tmin, and tobs in weather_data\n",
    "\n",
    "# Check how many records exist for tmax, tmin, and \n",
    "# tobs and their missing values.\n",
    "print(weather_data[['tmax', 'tmin', 'tobs']].isnull().sum())\n",
    "\n",
    "# Count non-missing records\n",
    "non_missing_counts = weather_data[['tmax', 'tmin', 'tobs']].count()\n",
    "print(non_missing_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae9ac0-b579-455b-a181-037fab35b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Stations Reporting Patterns\n",
    "\n",
    "# Group by station (iata) and count reports\n",
    "station_counts = weather_data.groupby('iata')[['tmax', 'tmin', 'tobs']].count()\n",
    "print(station_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbbe3f0-73d6-4ea8-9d95-5073efea0d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_tmax_tmin = station_counts[station_counts['tobs'] == 0]\n",
    "print(f\"Stations reporting only tmax and tmin: {only_tmax_tmin.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2afa42-3320-43e8-aa96-457f6c9745e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_tobs = station_counts[station_counts[['tmax', 'tmin']].isnull().any(axis=1)]\n",
    "print(f\"Stations reporting only tobs: {only_tobs.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b68f70d-f329-4210-8205-aece3abbdd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze recording patterns\n",
    "def recording_pattern(row):\n",
    "    if pd.notnull(row['tmax']) and pd.notnull(row['tmin']) and pd.isnull(row['tobs']):\n",
    "        return 'tmax_tmin_only'\n",
    "    elif pd.isnull(row['tmax']) and pd.isnull(row['tmin']) and pd.notnull(row['tobs']):\n",
    "        return 'tobs_only'\n",
    "    elif pd.notnull(row['tmax']) and pd.notnull(row['tmin']) and pd.notnull(row['tobs']):\n",
    "        return 'all_recorded'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "weather_data['recording_pattern'] = weather_data[['tmax', 'tmin', 'tobs']].apply(recording_pattern, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66faba5e-66f7-43fc-8466-9c866a1b5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# count recording patterns\n",
    "pattern_counts = weather_data['recording_pattern'].value_counts()\n",
    "print(pattern_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c502e42-d499-4452-9edb-03ccf93fcc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  bar chart to visualize the distribution of recording patterns\n",
    "\n",
    "pattern_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Recording Patterns of Weather Stations')\n",
    "plt.xlabel('Recording Pattern')\n",
    "plt.ylabel('Number of Stations')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3beaf3e-03ac-4a6a-938c-716643b80de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=weather_data[weather_data['recording_pattern'] != 'tobs_only'], x='recording_pattern', y='tmax')\n",
    "plt.title('Comparison of tmax Across Recording Patterns')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=weather_data[weather_data['recording_pattern'] != 'tobs_only'], x='recording_pattern', y='tmin')\n",
    "plt.title('Comparison of tmin Across Recording Patterns')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d6aa34-9833-483b-8d9f-1077999811e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop tobs column\n",
    "weather_data.drop(columns=['tobs'], inplace=True)\n",
    "print(weather_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f9f7f-4b68-41a9-8df2-75c1868738b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names\n",
    "flights_data.columns = flights_data.columns.str.lower().str.replace(' ', '_')\n",
    "weather_data.columns = weather_data.columns.str.lower().str.replace(' ', '_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb376e71-c4c3-451b-91e6-f5553811aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many records exist and their missing values.\n",
    "print(weather_data.isnull().sum())\n",
    "\n",
    "# Count non-missing records\n",
    "non_missing_counts = weather_data.count()\n",
    "print(non_missing_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6449a4-f35c-4151-9355-5af83caf43ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many records exist and their missing values.\n",
    "print(flights_data.isnull().sum())\n",
    "\n",
    "# Count non-missing records\n",
    "non_missing_counts = flights_data.count()\n",
    "print(non_missing_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb93f866-044c-4a3d-ae5b-8ca0740b1aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flights_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a2fb75-ddc2-4af4-89d2-c9e9ce34e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd236c35-013d-4ac3-a850-9c0f46abb711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary\n",
    "day_mapping = {\n",
    "    1: 'Monday',\n",
    "    2: 'Tuesday',\n",
    "    3: 'Wednesday',\n",
    "    4: 'Thursday',\n",
    "    5: 'Friday',\n",
    "    6: 'Saturday',\n",
    "    7: 'Sunday'\n",
    "}\n",
    "\n",
    "# Convert numeric days to day names\n",
    "flights_data['day_of_week'] = flights_data['day_of_week'].replace(day_mapping)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(flights_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2071c-37b4-4747-9536-46fa5ec3f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flight Delays: Analyze the distribution of flight delays.\n",
    "sns.histplot(flights_data['actual_elapsed_time'] - flights_data['crs_elapsed_time'], bins=50)\n",
    "plt.title('Distribution of Flight Delays')\n",
    "\n",
    "# Set the limits for the x-axis\n",
    "plt.xlim(-100, 100)  # Adjust based on the distribution\n",
    "\n",
    "plt.xlabel('Delay (minutes)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae28b2-fd56-42aa-a00d-1766726c055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather Variables: Analyze temperature and precipitation.\n",
    "\n",
    "sns.boxplot(x='tmax', data=weather_data)\n",
    "plt.title('Max Temperature Distribution')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x='prcp', data=weather_data)\n",
    "plt.title('Precipitation Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3941e6-551f-4a9e-ba8d-add9abbe8afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between delays and weather:\n",
    "combined_data = flights_data.merge(weather_data, left_on=['date', 'origin_iata'], right_on=['date', 'iata'], how='left')\n",
    "\n",
    "# Calculate the delay\n",
    "combined_data['delay'] = combined_data['actual_elapsed_time'] - combined_data['crs_elapsed_time'] \n",
    "\n",
    "# Create the scatterplot\n",
    "sns.scatterplot(x='tmax', y='delay', data=combined_data)\n",
    "plt.title('Flight Delay vs Max Temperature')\n",
    "plt.xlabel('Max Temperature (°F)')\n",
    "plt.ylabel('Delay (minutes)')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952a68e-3228-46ac-9910-b40dd14afea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge for flight data for origin\n",
    "origin_data = flights_data.merge(\n",
    "    weather_data,\n",
    "    left_on=['date', 'origin_iata'],\n",
    "    right_on=['date', 'iata'],\n",
    "    how='left',\n",
    "    suffixes=('', '_origin')\n",
    ")\n",
    "\n",
    "# Merge for flight data for destination\n",
    "dest_data = flights_data.merge(\n",
    "    weather_data,\n",
    "    left_on=['date', 'dest_iata'],\n",
    "    right_on=['date', 'iata'],\n",
    "    how='left',\n",
    "    suffixes=('', '_dest')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7657bb5-69b0-4774-b0f6-9b85bb1daaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between delays and weather:\n",
    "combined_data = flights_data.merge(weather_data, left_on=['date', 'dest_iata'], right_on=['date', 'iata'], how='left')\n",
    "\n",
    "# Calculate the delay\n",
    "combined_data['delay'] = combined_data['actual_elapsed_time'] - combined_data['crs_elapsed_time'] \n",
    "\n",
    "# Create the scatterplot\n",
    "sns.scatterplot(x='tmax', y='delay', data=combined_data)\n",
    "plt.title('Flight Delay vs Max Temperature')\n",
    "plt.xlabel('Max Temperature (°F)')\n",
    "plt.ylabel('Delay (minutes)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06986557-4c63-4760-afbc-a7cf9d19d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dccb01d-b416-4dde-8a17-6291c593f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460fc8c9-e273-4668-ac90-8134e3a3d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# can't merge dest_data and arrival_data due to memory errors\n",
    "# Function to process and merge data for a range of dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35eacf7-e933-4e77-9622-cfb6daf7a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print common columns between origin_data and dest_data\n",
    "common_columns = set(origin_data.columns) & set(dest_data.columns)\n",
    "print(common_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ce14b-fa34-4648-8ddf-a370a3ce7d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(origin_data.duplicated().sum())\n",
    "print(dest_data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94f7b2-c1c2-4e29-b871-24ce2abc06a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(origin_data.columns)\n",
    "print(origin_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e35c98-fb11-4700-8c76-4de1fc72924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dest_data.columns)\n",
    "print(dest_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526359f-df68-4cda-a1f5-d726f9d0bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicate columns\n",
    "\n",
    "# Create a function to identify columns with identical content\n",
    "def get_duplicate_columns(df1, df2):\n",
    "    duplicates = []\n",
    "    for col1 in df1.columns:\n",
    "        for col2 in df2.columns:\n",
    "            if df1[col1].equals(df2[col2]):\n",
    "                duplicates.append((col1, col2))\n",
    "    return duplicates\n",
    "\n",
    "# Get the list of duplicate columns\n",
    "duplicate_columns = get_duplicate_columns(origin_data, dest_data)\n",
    "\n",
    "# Step 2: Print duplicate columns for verification\n",
    "print(\"Duplicate columns based on content:\")\n",
    "for orig_col, dest_col in duplicate_columns:\n",
    "    print(f\"Origin Column: {orig_col} | Destination Column: {dest_col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb028cc7-6162-48fd-9fd5-659da2a409e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate delay for origin data\n",
    "origin_data['delay'] = origin_data['actual_elapsed_time'] - origin_data['crs_elapsed_time']\n",
    "\n",
    "# Keep only necessary columns: 'date', 'iata', and 'delay'\n",
    "origin_delay = origin_data[['date', 'iata', 'delay']]\n",
    "\n",
    "print(origin_delay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb7879-5fdc-44a8-b7d2-d20a265fdaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate delay for destination data\n",
    "dest_data['delay'] = dest_data['actual_elapsed_time_dest'] - dest_data['crs_elapsed_time_dest']\n",
    "\n",
    "# Keep only necessary columns: 'date', 'iata', and 'delay'\n",
    "dest_delay = dest_data[['date', 'iata', 'delay']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b22da8-8e8b-4bbb-a281-05d28a5ead7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dest_delay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c86842f-680b-4a8a-8b97-bc222d576167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of origin_delay: {len(origin_data['delay'])}\")\n",
    "print(f\"Length of dest_delay: {len(dest_data['delay'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8304ca0-bb60-408a-bc84-ac92e34c8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming origin_delay and dest_delay are Series with corresponding indexes\n",
    "# Create a DataFrame with both delays\n",
    "delay_data = pd.DataFrame({\n",
    "    'origin_delay': origin_delay,\n",
    "    'dest_delay': dest_delay\n",
    "})\n",
    "\n",
    "# Now filter the rows where the delays are not equal\n",
    "mismatched_delays = delay_data[delay_data['origin_delay'] != delay_data['dest_delay']]\n",
    "\n",
    "# Display the mismatched rows\n",
    "print(mismatched_delays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2dc05-1d84-4277-a03b-55cb6140e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flights_data.columns)\n",
    "print(flights_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe9aea-f9f0-4e7b-8aec-a3812baa5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_data.columns)\n",
    "print(weather_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e84fb3-80f7-46d8-ad40-3dc66ec8cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to check for null values\n",
    "columns_to_fill = ['prcp', 'tmax', 'tmin', 'elevation']\n",
    "\n",
    "# Fill missing values with the median for each specified column\n",
    "for col in columns_to_fill:\n",
    "    median_value = weather_data[col].median()\n",
    "    weather_data[col] = weather_data[col].fillna(median_value)\n",
    "\n",
    "# Interpolate remaining null values (if any)\n",
    "weather_data[columns_to_fill] = weather_data[columns_to_fill].interpolate()\n",
    "\n",
    "# Print the count of null values in the specified columns\n",
    "null_counts = weather_data[columns_to_fill].isnull().sum()\n",
    "\n",
    "print(\"Null values in specified columns:\")\n",
    "print(null_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5941b0d-910c-44a9-9135-b08db53e891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e42576-9e74-41c0-b766-db9e2a259747",
   "metadata": {},
   "source": [
    "Missing Data in weather_data: If weather_data does not have entries for specific dates and corresponding iata codes, any flight from flights_data that matches those criteria will not find a match, leading to NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa8d27-5a6d-431b-8e60-9bd4535d3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = combined_data.isnull()\n",
    "print(nan_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd089f6-8e94-4427-9d08-45eb7e12ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flights_data['origin_iata'].unique())\n",
    "print(weather_data['iata'].unique())\n",
    "print(flights_data.shape)\n",
    "print(weather_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd5d4d-45c1-47f1-8dc9-a0ad4b51de06",
   "metadata": {},
   "source": [
    "It seems there are iata codes in weather_data that do not match the origin_iata codes in flights_data. For instance, if flights_data has 'cvg' as origin_iata but weather_data does not have an entry for 'cvg' on that date, the merge will result in NaN for the iata column in the combined_data for those flights. The shapes indicate that flights_data has significantly more rows (4,009,949) than weather_data (139,012). This implies that many flights may not have corresponding weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6453606c-7f0f-4514-9c51-09675a999a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = combined_data[combined_data['iata'].isnull()]\n",
    "print(nan_rows[['date', 'origin_iata','dest_iata']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0df875-a760-4a11-b7dc-53f13705ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the specific columns to view\n",
    "columns_of_interest = ['iata', 'origin_iata', 'dest_iata']\n",
    "selected_data = combined_data[columns_of_interest]\n",
    "\n",
    "# Display the selected columns\n",
    "print(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e2b24-d123-4457-b66e-1f006930fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_iata = set(flights_data['origin_iata'].unique()) - set(weather_data['iata'].unique())\n",
    "print(unmatched_iata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe2eca-75f3-4e81-b646-d7f66f663c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dates = set(flights_data['date']) - set(weather_data['date'])\n",
    "print(missing_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac11263-350f-4df3-8c1d-81a3a50d052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2473be30-d8a8-4cbe-b2bb-0abc08289b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to remove\n",
    "columns_to_remove = ['iata', 'recording_pattern', 'latitude', 'longitude']\n",
    "\n",
    "# Create a new DataFrame without the specified columns\n",
    "cleaned_combined_data = combined_data.drop(columns=columns_to_remove)\n",
    "\n",
    "# Optionally, check the first few rows of the new DataFrame\n",
    "print(cleaned_combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86598f35-faea-4060-866c-6a330b1efba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474af74-b9e4-46d7-a73c-57b90c4a06a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "file_path = r'C:\\Users\\hopeh\\Desktop\\data_science_bootcamp\\flight_times_capstone\\cleaned_combined_data_v1.csv'\n",
    "\n",
    "cleaned_combined_data.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851433ce-6db1-470e-b135-46ba7b317bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_combined_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d4ca0e-9b31-4bb6-bb14-77c28d27af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb7df2-bf84-4036-accc-3204962db81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename to flights_weather_df\n",
    "flights_weather_df = cleaned_combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e324cbf-a35b-4de2-ac4e-4bb3c59a15e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delays by days of week\n",
    "# Calculate the delay\n",
    "flights_weather_df['delay'] = flights_weather_df['actual_elapsed_time'] - flights_weather_df['crs_elapsed_time']\n",
    "\n",
    "# Delays by days of week\n",
    "sns.boxplot(x='day_of_week', y='delay', data=flights_weather_df)\n",
    "plt.title('Flight Delays by Day of the Week')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Delay (minutes)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6842617-0264-4c02-893d-e9c46b2e8729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns for correlation\n",
    "numeric_data = flights_weather_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = numeric_data.corr()\n",
    "\n",
    "# Heatmap of correlation\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr, annot=False, cmap='coolwarm', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371640b8-6aca-4fb3-9655-5df05d2f0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flight delays by state\n",
    "\n",
    "\n",
    "# Flight delays by state\n",
    "avg_delay_by_state = flights_weather_df.groupby('origin_state')['delay'].mean().reset_index()\n",
    "\n",
    "# Create the bar plot\n",
    "sns.barplot(x='origin_state', y='delay', data=avg_delay_by_state)\n",
    "plt.title('Average Flight Delay by State')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Average Delay (minutes)')\n",
    "plt.xlabel('Origin State')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa53e24c-6d17-41d9-a491-29bc959b69e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Flight delays by latitudes and longitudes\n",
    "\n",
    "# flights_data['date'] = pd.to_datetime(flights_data['date'])\n",
    "\n",
    "# # Create a season column\n",
    "# def get_season(month):\n",
    "#     if month in [12, 1, 2]:\n",
    "#         return 'Winter'\n",
    "#     elif month in [3, 4, 5]:\n",
    "#         return 'Spring'\n",
    "#     elif month in [6, 7, 8]:\n",
    "#         return 'Summer'\n",
    "#     else:\n",
    "#         return 'Fall'\n",
    "\n",
    "# flights_data['season'] = flights_data['date'].dt.month.apply(get_season)\n",
    "\n",
    "# # Combine relevant data\n",
    "# data_for_correlation = flights_data[['latitude', 'longitude', 'arrival_delay', 'departure_delay', 'season']]\n",
    "\n",
    "# # Correlation Analysis\n",
    "# # Calculate correlation coefficients by season\n",
    "# correlation_results = data_for_correlation.groupby('season').corr().reset_index()\n",
    "\n",
    "# # Extracting the relevant correlation data\n",
    "# arrival_corr = correlation_results[correlation_results['level_1'].isin(['arrival_delay', 'latitude', 'longitude'])]\n",
    "# departure_corr = correlation_results[correlation_results['level_1'].isin(['departure_delay', 'latitude', 'longitude'])]\n",
    "\n",
    "# # Visualization\n",
    "# plt.figure(figsize=(14, 6))\n",
    "\n",
    "# # Scatter plot for Arrival Delay vs Latitude\n",
    "# plt.subplot(1, 2, 1)\n",
    "# sns.scatterplot(data=flights_data, x='latitude', y='arrival_delay', hue='season', alpha=0.7)\n",
    "# plt.title('Arrival Delay vs Latitude by Season')\n",
    "# plt.axhline(0, color='red', linestyle='--')\n",
    "# plt.xlabel('Latitude')\n",
    "# plt.ylabel('Arrival Delay (minutes)')\n",
    "\n",
    "# # Scatter plot for Departure Delay vs Latitude\n",
    "# plt.subplot(1, 2, 2)\n",
    "# sns.scatterplot(data=flights_data, x='latitude', y='departure_delay', hue='season', alpha=0.7)\n",
    "# plt.title('Departure Delay vs Latitude by Season')\n",
    "# plt.axhline(0, color='red', linestyle='--')\n",
    "# plt.xlabel('Latitude')\n",
    "# plt.ylabel('Departure Delay (minutes)')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Print correlation coefficients\n",
    "# # calculate correlations between delays and latitude/longitude. \n",
    "# # The results are grouped by season to see how the relationships change.\n",
    "# print(\"Arrival Delay Correlation with Latitude:\")\n",
    "# print(arrival_corr)\n",
    "# print(\"\\nDeparture Delay Correlation with Latitude:\")\n",
    "# print(departure_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd1a6b1-4ed3-48c7-b93e-98f843e79779",
   "metadata": {},
   "source": [
    "Some seasonal correlations are slightly positive (e.g., Summer Arrival Delay: 0.042, Winter Departure Delay: 0.009668), but these values are still weak.\n",
    "\n",
    "Similar to latitude, longitude also shows low correlation with delays. Most values are close to zero, indicating no significant relationship.\n",
    "\n",
    "Explore other factors that might impact delays, such as weather conditions (precipitation, snow), airport traffic, or operational factors (e.g., carrier delays).\n",
    "\n",
    "Consider using statistical models (like linear regression) to analyze the influence of various factors, including latitude, longitude, and weather, on flight delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134da6b-2c90-41d4-88ce-e69c7bb7aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'date' is in your DataFrame and is in string format\n",
    "flights_weather_df['date'] = pd.to_datetime(flights_weather_df['date'])\n",
    "\n",
    "# Define a function to get the season based on the month\n",
    "def get_season(date):\n",
    "    month = date.month\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'summer'\n",
    "    else:\n",
    "        return 'fall'\n",
    "\n",
    "# Apply the function to create the season column\n",
    "flights_weather_df['season'] = flights_weather_df['date'].apply(get_season)\n",
    "\n",
    "# Now sample the data again\n",
    "sampled_data = flights_weather_df.sample(frac=0.1, random_state=1)\n",
    "\n",
    "# Scatter plot for Arrival Delay vs Latitude (using sampled data)\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(data=sampled_data, x='dest_latitude', y='arrival_delay', hue='season', alpha=0.7)\n",
    "plt.title('Arrival Delay vs Latitude by Season (Sampled)')\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel('Arrival Delay (minutes)')\n",
    "\n",
    "# Remove legend\n",
    "plt.legend([], [], frameon=False)\n",
    "\n",
    "# Scatter plot for Departure Delay vs Latitude (using sampled data)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(data=sampled_data, x='origin_latitude', y='departure_delay', hue='season', alpha=0.7)\n",
    "plt.title('Departure Delay vs Latitude by Season (Sampled)')\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel('Departure Delay (minutes)')\n",
    "\n",
    "# Remove legend\n",
    "plt.legend([], [], frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cec590-afa7-4133-a3a1-744b5519b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numeric columns that aren't needed for correlation\n",
    "flights_weather_df_numeric = flights_weather_df.select_dtypes(include=[np.number])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c542e5e-9fdf-4a96-9848-59dae8520643",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = flights_weather_df_numeric.corr()\n",
    "print(correlation_matrix[['arrival_delay', 'departure_delay']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071b4bf3-3490-4bcc-8578-23d6db397cdc",
   "metadata": {},
   "source": [
    "Wheels On & Arrival Delay: The strongest correlation with arrival_delay is with wheels_on (0.276). This indicates that as the wheels-on time increases, arrival delays may also increase.\n",
    "Departure Delay & Departure Time: There’s a notable positive correlation (0.245) between dep_time and departure_delay, suggesting that later departure times are associated with greater delays.\n",
    "Arrival Delay and Departure Delay: There’s a moderate correlation (0.156) between arrival_delay and departure_delay, which is expected since delays often propagate through a flight schedule.\n",
    "Weather Variables: The correlations with weather variables (prcp, snow, snwd, tmax, tmin) are quite low, indicating that weather may not have a significant impact on delays in this dataset.\n",
    "Other Factors: Variables like crs_dep_time, crs_arr_time, and total_delay_time have negative correlations with delays, which might suggest timing discrepancies play a role.Visualize Relationships: Create scatter plots or pair plots to visualize relationships between key variables, especially those with stronger correlations. This can help identify any non-linear patterns or clusters.\n",
    "\n",
    "Feature Engineering: Consider creating new features based on the existing ones. For example, you could create interaction terms between departure and arrival times, or consider categorizing times into \"early,\" \"on-time,\" and \"late.\"\n",
    "\n",
    "Modeling: If you're interested in predicting delays, consider building regression models using arrival_delay and departure_delay as your target variables. Use features with significant correlations as predictors.\n",
    "\n",
    "Explore Seasonal Effects: Given that delays might vary by season, consider analyzing delays over time, or create a model that includes seasonal effects if you haven’t already.\n",
    "\n",
    "Handle Missing Values: Check if any of the features with NaN values (like flights) might need imputation or removal from the analysis, as they can affect model performance.\n",
    "\n",
    "Group Analysis: Consider grouping by other categorical variables like origin_state, dest_state, or carrier to see if certain airlines or routes consistently perform better or worse in terms of delays.\n",
    "\n",
    "Evaluate Multicollinearity: Since some features might be correlated with each other, it may be worth investigating multicollinearity, especially if you proceed to modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b464e-f801-4c38-9717-d2382b4baa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_weather_df['season'] = flights_weather_df['date'].dt.month % 12 // 3 + 1\n",
    "# Mapping months to seasons\n",
    "season_mapping = {\n",
    "    1: 'winter',\n",
    "    2: 'spring',\n",
    "    3: 'summer',\n",
    "    4: 'fall'\n",
    "}\n",
    "flights_weather_df['season'] = flights_weather_df['season'].map(season_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db931f-4ea9-4612-990a-41ab3c331a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_delays = flights_weather_df.groupby('season')[['arrival_delay', 'departure_delay']].mean()\n",
    "print(seasonal_delays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a53069d-82b2-4997-957b-db646f89ab15",
   "metadata": {},
   "source": [
    "Analysis of Seasonal Delays\n",
    "\n",
    "Fall: Average arrival delay of about -12.40 minutes and a departure delay of about 2.84 minutes.\n",
    "Spring: Average arrival delay of about -17.37 minutes, with a slightly higher departure delay.\n",
    "Summer: The highest average arrival delay of about -24.16 minutes, but the departure delay is lower than in Spring.\n",
    "Winter: Similar to Fall, with an average arrival delay of about -12.01 minutes and a higher departure delay than Fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5564a86d-ac77-4964-8c2d-872a99e7b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_delays.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Average Arrival and Departure Delays by Season')\n",
    "plt.ylabel('Delay (minutes)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.legend(title='Delay Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c0952-82fe-4750-82df-a38d5bb7cb7d",
   "metadata": {},
   "source": [
    "Compare the seasonal delays with other factors such as weather conditions or day of the week to identify any correlations.\n",
    "Investigate if the delays are statistically significant between seasons using ANOVA or similar statistical tests.\n",
    "Look into specific flights or routes that tend to have more significant delays in certain seasons.\n",
    "Consider analyzing potential reasons for the delays, like weather conditions or operational issues during specific times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ebdfb1-e2d8-417e-8528-edd15bbebc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print correlation coefficients\n",
    "# # calculate correlations between delays and latitude/longitude. \n",
    "# # The results are grouped by season to see how the relationships change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e436d2-6959-40b9-be74-aaa8f06adacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_weather_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec34f5-8aaa-4700-a770-f95d419ca214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots show the relationship between elevation and both arrival \n",
    "# and departure delays, colored by season. This helps visualize any patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd540c0c-79a9-40c3-b96d-ee7954b0b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot delays vs elevation\n",
    "def plot_delay_vs_elevation(data):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Arrival Delay\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.scatterplot(data=data, x='elevation', y='arrival_delay', hue='season', alpha=0.7)\n",
    "    plt.title('Arrival Delay vs Elevation by Season')\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.xlabel('Elevation (feet)')\n",
    "    plt.ylabel('Arrival Delay (minutes)')\n",
    "\n",
    "    # Departure Delay\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.scatterplot(data=data, x='elevation', y='departure_delay', hue='season', alpha=0.7)\n",
    "    plt.title('Departure Delay vs Elevation by Season')\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.xlabel('Elevation (feet)')\n",
    "    plt.ylabel('Departure Delay (minutes)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the plotting function with the correct DataFrame\n",
    "plot_delay_vs_elevation(flights_weather_df)\n",
    "\n",
    "# Calculate Correlation Coefficients\n",
    "elevation_delay_corr = flights_weather_df.groupby('season')[['elevation', 'arrival_delay', 'departure_delay']].corr()\n",
    "elevation_delay_corr = elevation_delay_corr.reset_index()\n",
    "\n",
    "# Extracting relevant correlation data\n",
    "arrival_elevation_corr = elevation_delay_corr[elevation_delay_corr['level_1'] == 'arrival_delay']\n",
    "departure_elevation_corr = elevation_delay_corr[elevation_delay_corr['level_1'] == 'departure_delay']\n",
    "\n",
    "# Print correlation coefficients\n",
    "print(\"Arrival Delay Correlation with Elevation:\")\n",
    "print(arrival_elevation_corr[['season', 'elevation', 'arrival_delay', 'level_1']])\n",
    "print(\"\\nDeparture Delay Correlation with Elevation:\")\n",
    "print(departure_elevation_corr[['season', 'elevation', 'departure_delay', 'level_1']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f757d8a-4693-4eb2-91be-5fe7da9da7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flight delays vs elevation analysis\n",
    "# Calculate Correlation Coefficients\n",
    "# Function to plot delays vs elevation\n",
    "def plot_delay_vs_elevation(data):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Arrival Delay\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.scatterplot(data=data, x='elevation', y='arrival_delay', hue='season', alpha=0.7)\n",
    "    plt.title('Arrival Delay vs Elevation by Season')\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.xlabel('Elevation (feet)')\n",
    "    plt.ylabel('Arrival Delay (minutes)')\n",
    "\n",
    "    # Departure Delay\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.scatterplot(data=data, x='elevation', y='departure_delay', hue='season', alpha=0.7)\n",
    "    plt.title('Departure Delay vs Elevation by Season')\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.xlabel('Elevation (feet)')\n",
    "    plt.ylabel('Departure Delay (minutes)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the plotting function with the correct DataFrame\n",
    "plot_delay_vs_elevation(flights_weather_df)\n",
    "\n",
    "# Calculate Correlation Coefficients\n",
    "elevation_delay_corr = flights_weather_df.groupby('season')[['elevation', 'arrival_delay', 'departure_delay']].corr()\n",
    "elevation_delay_corr = elevation_delay_corr.reset_index()\n",
    "\n",
    "# Extracting relevant correlation data\n",
    "arrival_elevation_corr = elevation_delay_corr[elevation_delay_corr['level_1'] == 'arrival_delay']\n",
    "departure_elevation_corr = elevation_delay_corr[elevation_delay_corr['level_1'] == 'departure_delay']\n",
    "\n",
    "# Print correlation coefficients\n",
    "print(\"Arrival Delay Correlation with Elevation:\")\n",
    "print(arrival_elevation_corr[['season', 'elevation', 'arrival_delay', 'level_1']])\n",
    "print(\"\\nDeparture Delay Correlation with Elevation:\")\n",
    "print(departure_elevation_corr[['season', 'elevation', 'departure_delay', 'level_1']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069cb7ec-ade1-490f-b2d1-e83d8419dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Ensure 'date' column is in datetime format\n",
    "flights_weather_df['date'] = pd.to_datetime(flights_weather_df['date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d04b3d1-7a6b-4913-8104-f5e3ecf5829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now, check if the columns exist and rename if necessary\n",
    "# Extract relevant columns after merging\n",
    "# Assuming the destination weather columns are suffixed with '_dest'\n",
    "\n",
    "# Print columns\n",
    "print(\"Columns in flights_weather_df:\")\n",
    "print(flights_weather_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e44c09-5bdf-43e5-bb3c-d514530df2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying outliers\n",
    "\n",
    "Q1 = flights_weather_df['total_delay_time'].quantile(0.25)\n",
    "Q3 = flights_weather_df['total_delay_time'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out outliers\n",
    "outliers = flights_weather_df[(flights_weather_df['total_delay_time'] < lower_bound) | (flights_weather_df['total_delay_time'] > upper_bound)]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=flights_data['total_delay_time'])\n",
    "plt.title('Box Plot of Total Delay Time')\n",
    "plt.axvline(0, color='red', linestyle='--')  # Line at zero for reference\n",
    "plt.show()\n",
    "\n",
    "print(\"Outliers:\")\n",
    "print(outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e14f1be-fc75-471b-b82e-26e19db30bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types of the columns\n",
    "print(flights_weather_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9923fc8a-a1c8-47f6-b365-8bb78f712da1",
   "metadata": {},
   "source": [
    "For All Flights\n",
    "\n",
    "Total Entries: Approximately 4 million records.\n",
    "\n",
    "Total Delay Time: The mean total delay time is negative (-5.32 minutes), indicating that, on average, flights arrived earlier than scheduled.\n",
    "Arrival and Departure Delays: Both have negative means (-16.59 for arrival delay), showing that many flights may have arrived early.\n",
    "Delay Variability: The standard deviations for delays are high, particularly for arrival_delay (191.32) and departure_delay (97.96), suggesting significant variability in delays.\n",
    "\n",
    "\n",
    "For Outliers\n",
    "\n",
    "Total Entries: Around 190,000 records identified as outliers.\n",
    "Total Delay Time: The mean total delay time is positive (22.83 minutes), indicating that these flights were delayed on average.\n",
    "Arrival Delay: The mean arrival delay is negative (-14.49 minutes), suggesting these flights still arrived early despite being categorized as outliers.\n",
    "Departure Delay: The mean departure delay is positive (13.57 minutes), indicating that these flights were delayed in their takeoff.\n",
    "\n",
    "\n",
    "Analyzing the Differences\n",
    "\n",
    "Flight Performance: The fact that outliers have a higher mean total delay time while having early arrival times indicates that these flights likely had significant delays during departure.\n",
    "Delay Types: The outliers have more pronounced variability in departure_delay, suggesting some flights experienced extreme delays compared to the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81377a6-81ad-43bc-835b-1766a40e21ea",
   "metadata": {},
   "source": [
    "Cancellation and Diversion:\n",
    "\n",
    "Both cancelled and diverted columns show only 0.0, indicating that there are no cancellations or diversions in your dataset. Remove from Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222358f4-829b-4a2d-b843-2d09e88e34ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'cancelled' and 'diverted' columns from the DataFrame\n",
    "flights_weather_df.drop(columns=['cancelled', 'diverted'], inplace=True)\n",
    "\n",
    "# Verify that the columns have been removed\n",
    "print(flights_weather_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b76067-547a-4d2f-a2c3-18eca97986f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85681730-bff2-49d0-bb59-989cf8710371",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5516b1e3-64c3-413d-9c00-a27d97e60618",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='arrival_delay', y='total_delay_time', data=flights_weather_df, alpha=0.6)\n",
    "plt.scatter(outliers['arrival_delay'], outliers['total_delay_time'], color='red', label='Outliers', alpha=0.7)\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.title('Total Delay Time vs Arrival Delay (Outliers in Red)')\n",
    "plt.xlabel('Arrival Delay (minutes)')\n",
    "plt.ylabel('Total Delay Time (minutes)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b920d-6f8a-4277-aaa4-a269b31374cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary Statistics for All Flights:\")\n",
    "print(flights_weather_df.describe())\n",
    "\n",
    "print(\"\\nSummary Statistics for Outliers:\")\n",
    "print(outliers.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe46794-6bdf-4273-b2e4-b5e69b21629a",
   "metadata": {},
   "source": [
    "The Bureau of Transportation Statistics (BTS) typically provides flight data in a standardized format, and the times are generally recorded in Coordinated Universal Time (UTC). This means that all departure and arrival times are expressed in a single time zone, allowing for consistent comparison across different flights and time zones.\n",
    "\n",
    "There should not be very many negative departure delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429b90b-c3d1-4f51-97e4-27d2965259d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove outliers based on IQR\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Columns to check for outliers\n",
    "delay_columns = ['total_delay_time', 'arrival_delay', 'departure_delay']\n",
    "\n",
    "# Remove outliers for each column\n",
    "for column in delay_columns:\n",
    "    flights_weather_df = remove_outliers(flights_weather_df, column)\n",
    "\n",
    "# Optionally, check the number of remaining rows\n",
    "print(f\"Remaining rows after outlier removal: {len(flights_weather_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c784dc6-e1ea-4273-82ca-86c4f9db5d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Summary Statistics for All Flights after removal:\")\n",
    "print(flights_weather_df.describe())\n",
    "\n",
    "print(\"\\nSummary Statistics for Outliers:\")\n",
    "print(outliers.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00acdf0c-918d-4bca-81d4-3621024d7487",
   "metadata": {},
   "source": [
    "Summary Statistics for All Flights (Post-Outlier Removal)\n",
    "\n",
    "Arrival Delay: The mean is approximately -9.43 minutes, indicating that flights tend to arrive slightly early on average.\n",
    "Departure Delay: The mean departure delay is -2.75 minutes, also suggesting early departures on average.\n",
    "\n",
    "Weather Variables:\n",
    "Average precipitation (prcp) is low (0.01298), and snow (snow) is minimal (mean 0.0187).\n",
    "Maximum temperatures (tmax) and minimum temperatures (tmin) are reasonable, with maximums reaching around 112°F.\n",
    "\n",
    "Summary Statistics for Outliers\n",
    "\n",
    "Arrival Delay: The mean arrival delay for outliers is -14.45 minutes, which indicates that these flights tend to arrive even earlier than the overall dataset.\n",
    "Departure Delay: Outliers show a significant positive mean departure delay of 13.58 minutes, indicating that these flights are more likely to be delayed when departing.\n",
    "\n",
    "Weather Variables:\n",
    "Outliers have higher average precipitation (0.02234) compared to the non-outlier flights, which may suggest that adverse weather conditions are affecting these flights.\n",
    "Notable snow values (mean 0.1297) indicate that these flights might be more impacted by winter weather.\n",
    "\n",
    "Key Comparisons\n",
    "Delays: The presence of outliers is associated with higher departure delays, suggesting that these flights may face different operational challenges compared to the majority.\n",
    "Weather Impact: Weather conditions appear to have a more significant effect on outlier flights, with greater precipitation and snow accumulation.\n",
    "\n",
    "\n",
    "Further Analysis: Conduct additional analyses to understand the factors leading to delays in outlier flights—particularly looking into operational issues, weather patterns, and airline performance.\n",
    "Data Visualization: Visualizing these statistics with box plots or histograms can help to better understand the distribution of delays and the impact of weather on flight performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093de6ec-2dfe-47d8-a4c0-05bc14540a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c27129-afe7-40e0-9676-327f882ac8f0",
   "metadata": {},
   "source": [
    "Key Observations\n",
    "Arrival Delay Correlations: There are very low correlations with elevation and precipitation. The strongest correlation (0.173481) is with departure delay. The temperature (tmax and tmin) shows a slight negative correlation, indicating that as temperatures rise, delays might slightly decrease.\n",
    "Departure Delay Correlations: Similar to arrival delays, departure delays have low correlations with most weather-related variables.  The strongest correlation with other factors is also with arrival delays.\n",
    "Snow and Precipitation: Snow (both at the origin and destination) shows some correlation with delays, particularly in the destination context. This suggests that snow could impact delays, even if the correlation is not very strong.\n",
    "Elevation: Elevation has a very low correlation with both arrival and departure delays, suggesting that it may not be a significant factor in delay analysis for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f27a777-7a91-45f1-92b7-650bc4afef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'flights_weather_df' is your DataFrame and it includes a column for airport identifiers\n",
    "# Example: 'airport_code' could be the column that identifies airports\n",
    "\n",
    "# Filter for non-zero snow or snwd values\n",
    "reported_snow = flights_weather_df[flights_weather_df['snow'] > 0]\n",
    "reported_snwd = flights_weather_df[flights_weather_df['snwd'] > 0]\n",
    "\n",
    "# Get unique airport identifiers for both cases\n",
    "unique_airports_snow = reported_snow['airport_code'].unique()\n",
    "unique_airports_snwd = reported_snwd['airport_code'].unique()\n",
    "\n",
    "# Combine unique airports from both lists\n",
    "all_reported_airports = set(unique_airports_snow).union(set(unique_airports_snwd))\n",
    "\n",
    "# Count the number of unique airports\n",
    "num_reported_airports = len(all_reported_airports)\n",
    "\n",
    "print(f\"Number of airports reporting snow or snwd: {num_reported_airports}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a05a4b-b85e-40bd-80b0-2dd01b5f040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for snow and snwd\n",
    "snow_stats = flights_weather_df['snow_origin, snow'].describe()\n",
    "snwd_stats = flights_weather_df['snwd'].describe()\n",
    "\n",
    "print(\"Snow statistics:\")\n",
    "print(snow_stats)\n",
    "print(\"Snow depth statistics (snwd):\")\n",
    "print(snwd_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7268998-f806-441e-908d-1c960a234661",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "heatmap = sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8})\n",
    "heatmap.set_title('Correlation Matrix of Flight Delays and Weather Variables', fontdict={'fontsize':18}, pad=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ee994-6227-42a1-a54b-3f240cee2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate whether a positive departure delay indicates a positive arrival delay\n",
    "# Visualize the relationship between departure delay and arrival delay\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=flights_data, x='departure_delay', y='arrival_delay', alpha=0.6)\n",
    "plt.title('Departure Delay vs Arrival Delay')\n",
    "plt.axhline(0, color='red', linestyle='--', label='Zero Arrival Delay')  # Reference line for zero arrival delay\n",
    "plt.axvline(0, color='blue', linestyle='--', label='Zero Departure Delay')  # Reference line for zero departure delay\n",
    "plt.xlabel('Departure Delay (minutes)')\n",
    "plt.ylabel('Arrival Delay (minutes)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the correlation coefficient\n",
    "correlation = flights_data['departure_delay'].corr(flights_data['arrival_delay'])\n",
    "print(f\"Correlation between Departure Delay and Arrival Delay: {correlation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0eaf7b-26ff-462d-be02-041db261ed95",
   "metadata": {},
   "source": [
    "While there is a slight tendency for flights that leave late to arrive late, other factors likely play a significant role in determining delays. This could include weather conditions, air traffic, or operational issues. \n",
    "\n",
    "Further Analysis:\n",
    "Time of Day: Analyze if departure and arrival delays vary by time of day. Morning flights might behave differently than evening flights.\n",
    "Airline Performance: Some airlines may have more consistent schedules than others. Analyze delays by airline.\n",
    "Route Analysis: Look into specific routes (origin-destination pairs) to see if certain routes experience more delays.\n",
    "Consider segmenting  analysis by different factors (e.g., season, weather conditions).\n",
    "Investigate Outliers: Look for flights that have significantly higher or lower delays to identify patterns or anomalies.\n",
    "\n",
    "A scatter plot of departure delay versus arrival delay could help visualize the relationship. Adding a regression line might clarify the trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551e1e9-d29d-48dd-b533-c52a0c872720",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=full_data, x='departure_delay', y='arrival_delay', alpha=0.6)\n",
    "plt.title('Departure Delay vs Arrival Delay')\n",
    "plt.xlabel('Departure Delay (minutes)')\n",
    "plt.ylabel('Arrival Delay (minutes)')\n",
    "plt.axhline(0, color='red', linestyle='--')  # Reference line for zero arrival delay\n",
    "plt.axvline(0, color='blue', linestyle='--')  # Reference line for zero departure delay\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f019b260-3749-423c-b722-aeee470c0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Analysis:\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data for clustering\n",
    "X = full_data[['departure_delay', 'arrival_delay']].dropna()\n",
    "\n",
    "# Fit K-Means with a specified number of clusters (e.g., 3)\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "full_data['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=full_data, x='departure_delay', y='arrival_delay', hue='cluster', palette='viridis', alpha=0.6)\n",
    "plt.title('Clusters of Departure vs Arrival Delays')\n",
    "plt.xlabel('Departure Delay (minutes)')\n",
    "plt.ylabel('Arrival Delay (minutes)')\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.axvline(0, color='blue', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5263dd-85d4-47f3-9d01-1a32aea56b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average delays for each cluster\n",
    "average_delays = full_data.groupby('cluster').agg({\n",
    "    'departure_delay': 'mean',\n",
    "    'arrival_delay': 'mean',\n",
    "    'elevation_origin': 'mean',  # You can add more columns if needed\n",
    "    'prcp_origin': 'mean',\n",
    "    'snow_origin': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(\"Average Delays by Cluster:\")\n",
    "print(average_delays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f1d40f-0903-4518-9e5e-f477791c6e48",
   "metadata": {},
   "source": [
    "Interpretation of Results\n",
    "Cluster 0:\n",
    "\n",
    "Departure Delay: Approximately 4.8 minutes\n",
    "Arrival Delay: Approximately 2.9 minutes\n",
    "Elevation: 176.7 feet\n",
    "Precipitation: 0.098 inches\n",
    "Snow: 0.037 inches\n",
    "This cluster has relatively low average delays for both departure and arrival.\n",
    "\n",
    "Cluster 1:\n",
    "\n",
    "Departure Delay: Approximately -87.8 minutes (indicating flights are departing early on average)\n",
    "Arrival Delay: Approximately -1314.4 minutes (indicating substantial early arrivals, which might need verification or further analysis)\n",
    "Elevation: 113.4 feet\n",
    "Precipitation: 0.174 inches\n",
    "Snow: 0.053 inches\n",
    "The negative values suggest that flights in this cluster are consistently arriving and departing significantly earlier than expected.\n",
    "\n",
    "Cluster 2:\n",
    "\n",
    "Departure Delay: Approximately -69.0 minutes\n",
    "Arrival Delay: Approximately 1296.9 minutes (also indicating significant early arrivals)\n",
    "Elevation: 98.0 feet\n",
    "Precipitation: 0.104 inches\n",
    "Snow: 0.078 inches\n",
    "Similar to Cluster 1, this cluster shows a pattern of early departures but also high arrival delays, suggesting a potential outlier situation that warrants closer examination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ec21c-4bff-4a08-8325-0dad5ee82720",
   "metadata": {},
   "source": [
    "Next Steps for Analysis\n",
    "Investigate Negative Delays:\n",
    "\n",
    "Check if there are any data entry errors or outliers leading to these extreme negative values. Review the raw data for clusters 1 and 2.\n",
    "Analyze Common Characteristics:\n",
    "\n",
    "Continue with the common characteristics analysis to see if certain airlines, routes, or times of day are predominant in these clusters. This could help explain the delays observed.\n",
    "Visualize Data:\n",
    "\n",
    "Create visualizations (e.g., box plots or scatter plots) to better understand the distributions of delays within each cluster and identify any patterns.\n",
    "Correlation Analysis:\n",
    "\n",
    "Analyze how factors such as weather conditions (precipitation and snow) correlate with delays in each cluster.\n",
    "Further Segment Analysis:\n",
    "\n",
    "If any interesting trends emerge from the above analyses, consider further segmenting the data based on these insights (e.g., by specific routes or airlines) to explore delays in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a0da2-42f4-4bfa-9e19-9abc52551909",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Look for common characteristics\n",
    "common_characteristics = full_data.groupby('cluster').agg({\n",
    "    'op_unique_carrier': lambda x: x.mode()[0],  # Most common airline in the cluster\n",
    "    'op_carrier_fl_num': lambda x: x.mode()[0],    # Most common flight number in the cluster\n",
    "    'dep_time': lambda x: x.mode()[0],  # Most common departure time\n",
    "    'arr_time': lambda x: x.mode()[0],  # Most common arrival time\n",
    "    'crs_dep_time': lambda x: x.mode()[0],  # Most common scheduled departure time\n",
    "    'crs_arr_time': lambda x: x.mode()[0],  # Most common scheduled arrival time\n",
    "    'actual_elapsed_time': lambda x: x.mode()[0]  # Most common length of elapsed flight times\n",
    "}).reset_index()\n",
    "\n",
    "print(\"\\nCommon Characteristics by Cluster:\")\n",
    "print(common_characteristics)\n",
    "\n",
    "# Merge average delays and common characteristics\n",
    "cluster_analysis = average_delays.merge(common_characteristics, on='cluster')\n",
    "print(\"\\nCluster Analysis Summary:\")\n",
    "print(cluster_analysis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63d890-dd95-48e7-a0c2-ed50348cfa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge the average delays and common characteristics\n",
    "cluster_analysis = average_delays.merge(common_characteristics, on='cluster')\n",
    "print(\"\\nCluster Analysis Summary:\")\n",
    "print(cluster_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebee7dd-e0f0-4484-b9fc-85042091deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the average delays per cluster\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=average_delays, x='cluster', y='arrival_delay', color='blue', alpha=0.6, label='Arrival Delay')\n",
    "sns.barplot(data=average_delays, x='cluster', y='departure_delay', color='orange', alpha=0.6, label='Departure Delay')\n",
    "plt.title('Average Arrival and Departure Delays by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Average Delay (minutes)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5e7835-2118-4511-bcc4-3fc3808beb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we use the available data to get a look at air traffic in each airport and how that may impact delays? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f313a0ab-782b-4ea4-a967-719b3628f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features to use for modeling, considering their correlation with delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39edcd8f-0f8c-4336-bb03-f2592e356146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrival_delay\n",
    "# departure_delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e46ab-5a57-470b-95ae-431ee1e8526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model preparation\n",
    "\n",
    "#Train-test split\n",
    "# Assuming full_data is your DataFrame with features and target\n",
    "X = full_data.drop(columns=['arrival_delay'])  # Features\n",
    "y = full_data['arrival_delay']  # Target variable\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Assuming full_data is your DataFrame with features and target\n",
    "X = full_data.drop(columns=['arrival_delay'])  # Features\n",
    "y = full_data['arrival_delay']  # Target variable\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1942419-cc0d-4cd3-b192-7d37844abb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize/standardize features as needed\n",
    "# \"Standardization (Z-score Normalization): Centers the feature \n",
    "# around 0 with a standard deviation of 1. This is often preferred\n",
    "# for algorithms like SVM, k-means, and PCA.\"\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler only on the training data and transform both train and test\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc228d72-0d8e-449e-a325-179c227f0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scaled data into DataFrames\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "# Save to CSV if needed\n",
    "X_train_scaled_df.to_csv('X_train_scaled.csv', index=False)\n",
    "X_test_scaled_df.to_csv('X_test_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23118c70-7359-45f3-bfd7-d38583496770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean, Sum, Count: For time-based features, calculate statistics over certain time windows.\n",
    "df['daily_mean_delay'] = df.groupby('date')['arrival_delay'].transform('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ffa7b-9419-4c73-97a8-b8f558572fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Investigate outliers\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Boxplot for Arrival Delay\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x=flights_data['arrival_delay'])\n",
    "plt.title('Boxplot of Arrival Delay')\n",
    "plt.xlabel('Arrival Delay (minutes)')\n",
    "\n",
    "# Boxplot for Departure Delay\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=flights_data['departure_delay'])\n",
    "plt.title('Boxplot of Departure Delay')\n",
    "plt.xlabel('Departure Delay (minutes)')\n",
    "\n",
    "# Boxplot for total time delayed\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=flights_data['total_delay_time'])\n",
    "plt.title('Boxplot of Total Time Delay')\n",
    "plt.xlabel('Departure Delay (minutes)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa508cdb-29fe-4185-9917-d7030f01c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the IQR (Interquartile Range) to find outliers\n",
    "\n",
    "def detect_outliers(data):\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "arrival_bounds = detect_outliers(flights_data['arrival_delay'])\n",
    "departure_bounds = detect_outliers(flights_data['departure_delay'])\n",
    "\n",
    "# Filter outliers\n",
    "arrival_outliers = flights_data[(flights_data['arrival_delay'] < arrival_bounds[0]) | \n",
    "                                 (flights_data['arrival_delay'] > arrival_bounds[1])]\n",
    "\n",
    "departure_outliers = flights_data[(flights_data['departure_delay'] < departure_bounds[0]) | \n",
    "                                   (flights_data['departure_delay'] > departure_bounds[1])]\n",
    "\n",
    "print(\"Number of arrival delay outliers:\", len(arrival_outliers))\n",
    "print(\"Number of departure delay outliers:\", len(departure_outliers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b1a0cf-b093-4745-bfba-e8c2304b8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#review weather data\n",
    "weather_data.columns  # Check available columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df12890-6a9e-4f45-a1b1-bce727bbaa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize potential outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=weather_data['temperature'])  # Replace with relevant column\n",
    "plt.title('Boxplot of Temperature')\n",
    "plt.xlabel('Temperature')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1a1d8d-5304-432b-9c8b-a784e9dda2b3",
   "metadata": {},
   "source": [
    "Investigate Delay Causes: Further analysis can identify reasons for significant delays, focusing on factors like weather conditions, airport congestion, and airline performance.\n",
    "Comparative Analysis: Compare delays across different airlines, airports, or time periods to identify patterns and areas for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d6e6a1-d210-4c9d-887a-da25d17191ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c358606f-a08a-4233-89ff-23175c56de65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f88494-3bd8-4229-8676-ba183dcba561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462e5b2-4157-46cf-98ff-ff2ea0394f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294788cb-c702-466b-8a75-6a1a4e232c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
